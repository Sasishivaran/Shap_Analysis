{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db4563-5c7e-4914-b8aa-96ad5f606e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: generate synthetic churn dataset, train a pipeline, save model and CSV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# 1) Create synthetic dataset\n",
    "np.random.seed(RANDOM_SEED)\n",
    "n = 1000\n",
    "df = pd.DataFrame({\n",
    "    \"customer_id\": [f\"CUST_{i:05d}\" for i in range(n)],\n",
    "    \"age\": np.random.randint(18, 80, size=n),\n",
    "    \"tenure_months\": np.random.randint(0, 72, size=n),\n",
    "    \"monthly_charges\": np.round(np.random.uniform(20, 150, size=n), 2),\n",
    "    \"num_support_tickets\": np.random.poisson(1.2, size=n),\n",
    "    \"contract_type\": np.random.choice([\"month-to-month\", \"one-year\", \"two-year\"], size=n, p=[0.6,0.25,0.15]),\n",
    "    \"payment_method\": np.random.choice([\"electronic_check\",\"mailed_check\",\"bank_transfer\",\"credit_card\"], size=n),\n",
    "    \"has_internet\": np.random.choice([0,1], size=n, p=[0.1,0.9])\n",
    "})\n",
    "\n",
    "# 2) Create target 'churn'\n",
    "logit = (\n",
    "    0.02 * (df[\"monthly_charges\"] - df[\"monthly_charges\"].mean()) +\n",
    "    -0.03 * (df[\"tenure_months\"]) +\n",
    "    0.5 * df[\"num_support_tickets\"] +\n",
    "    0.6 * (df[\"contract_type\"] == \"month-to-month\").astype(int) +\n",
    "    0.3 * (df[\"has_internet\"] == 0).astype(int)\n",
    ")\n",
    "prob = 1 / (1 + np.exp(- ( -1.0 + logit / 10 )))\n",
    "df[\"churn\"] = (np.random.rand(n) < prob).astype(int)\n",
    "\n",
    "# 3) Shuffle rows and save CSV\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "df.to_csv(\"customer_data.csv\", index=False)\n",
    "print(\"Saved customer_data.csv with shape:\", df.shape)\n",
    "\n",
    "# 4) Prepare features and pipeline\n",
    "feature_cols = [\"age\", \"tenure_months\", \"monthly_charges\", \"num_support_tickets\", \"contract_type\", \"payment_method\", \"has_internet\"]\n",
    "X = df[feature_cols]\n",
    "y = df[\"churn\"]\n",
    "\n",
    "numeric_features = [\"age\", \"tenure_months\", \"monthly_charges\", \"num_support_tickets\", \"has_internet\"]\n",
    "categorical_features = [\"contract_type\", \"payment_method\"]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "# Use sparse_output=False for newer scikit-learn; if your sklearn is older, you can use sparse=False\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "# 5) Train pipeline\n",
    "pipeline.fit(X, y)\n",
    "print(\"Trained pipeline.\")\n",
    "\n",
    "# 6) Show feature names after preprocessing (robust across sklearn versions)\n",
    "try:\n",
    "    feat_names = pipeline.named_steps[\"prep\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback: build feature names manually\n",
    "    cat_names = pipeline.named_steps[\"prep\"].named_transformers_[\"cat\"].get_feature_names_out(categorical_features)\n",
    "    feat_names = list(numeric_features) + list(cat_names)\n",
    "print(\"Number of features after preprocessing:\", len(feat_names))\n",
    "print(feat_names[:20])\n",
    "\n",
    "# 7) Save model\n",
    "joblib.dump(pipeline, \"churn_model.pkl\")\n",
    "print(\"Saved churn_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shapenv)",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
